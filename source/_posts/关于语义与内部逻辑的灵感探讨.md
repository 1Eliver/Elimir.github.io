---
title: 关于语义与内部逻辑的灵感探讨
date: 2025-03-06 11:41:26
tags: ["灵感","认知拆分工程"]
categories: 杂谈
---

# 关于语义与内部逻辑的灵感探讨

今天在阅读《Experience-Grounded Semantics: A theory for intelligent systems》时突有所感，我们的系统是否能够实现其中`自动推理系统`所包含的基本部分：

>   An automatic (computerized) reasoning system usually consists of the following major components: 
>
>   一个自动(计算机化)推理系统通常包括以下主要组成部分: 
>
>   • a formal language for (internal) knowledge representation and (external) communication with the environ ment, 
>
>   • 一种用于(内部)知识表示和(外部)与环境通信的形式语言， 
>
>   • asemantic theory that links the language to the environment, 
>
>   • 一种将语言与环境相联系的语义理论， 
>
>   • aset of inference rules that derives new knowledge from given knowledge, and answer questions according to available knowledge, 
>
>   • 一套推理规则，能够从已知知识中推导出新知识，并根据现有知识回答问题， 
>
>   • amemory structure that stores the knowledge, questions, and intermediate results, 
>
>   • 一种存储知识、问题和中间结果的记忆结构， 
>
>   • acontrol strategy that decides what tasks to carry out and what rules to apply in each step. 
>
>   • 一种控制策略，决定在每个步骤中执行哪些任务以及应用哪些规则。
>
>   [Experience-Grounded Semantics: A theory for intelligent systems - Pei Wang]

## 关于形式语言

这里主要聚焦于`内部的知识表示`与`外部与环境通信`

这里对本文的两种歧义分别是`系统与外界（人）的交流`或是`语言本身与语言表达主题的对应`

### 系统与外界的交流

基于我对本系统的最初设想以及现在的进展定位，我认为系统内部的知识表达与外界（人）的通信在同一层面时是基于同一种符号语言的（解释：这里的符号语言可以是图片符号，音频信息单位符号，文字语言字符符号等……这里的符号只是一个代指，指可以组成串或链状的元素，聚合后可以成为信息的载体）

我认为知识表达与对外界的交流的本质是相同的，都是信息的传递，唯一的区别是内在的知识表达可以使用符号的联系直接表达（表达为通路等形式的聚合），而对外界的交流，我认为需要将这种通路的复杂聚合形式（符号等单位的多种聚合就是外界的信息在系统内部的表达形式）转化为交流同一层面的符号或者交流中指定形式的符号（“语言”对应）

### 语言本身与语言表达主体的对应

>The basic of model-theoretic semantics can be roughly described as the following. For a formal language L , a model Mconsists of descriptions about objects and their factual relations in a domain. The descriptions are written in another language Lm, which is a meta-language, and can either be a natural language, like English, or another formal language. An interpretation I maps the words in L onto the objects and relations in M . According to this theory, the meaning of a word in L is defined as its image in M under I , and whether a statement in L is true is determined by whether it is mapped by I onto a fact in M . 
>
>模型论语义学的基础可以大致描述如下。对于一个形式语言L，一个模型M包括关于领域中对象及其事实关系的描述。这些描述用另一种语言Lm书写，Lm是一种元语言，可以是自然语言，如英语，也 可以是另一种形式语言。一个解释I将L中的词汇映射到M中的对象和关系上。根据这一理论，L中一个词的意义被定义为它在M下I的像，而L中一个陈述是否为真，取决于它是否被I映射到M中的一个事实上。
>
>[Experience-Grounded Semantics: A theory for intelligent systems - Pei Wang]

本文中的语言本身与语言表达主体的对应也可以类比这个原理，但不尽相同——本项目中的知识储存模式并不是储存表达知识的符号链，而是储存信息本身——我们捕捉关联，而不是符号的链式表达。

>   长期记忆在本项目中想象为是一种`Nosql DB`形式的数据库，其数据存储结构是图，图中节点是不同种类的信息符号，而节点之间的连接有很多种形成的方式
>
>   [突发奇想的新架构 - Elimir]

形式语言L在本项目中的存在形式是`符号链`

如一段语言：“雪是白色的”，它在本系统中的存在形式可能就如下图：

[![pEYhlfP.png](https://s21.ax1x.com/2025/03/06/pEYhlfP.png)](https://imgse.com/i/pEYhlfP)

而所形容的模型M的存在在本系统中可能如下图

[![pEY5nPI.png](https://s21.ax1x.com/2025/03/06/pEY5nPI.png)](https://imgse.com/i/pEY5nPI)

（注释：其中固定搭配的词语[这里称作强关系符号链]成同一颜色，而基本无关联的符号标注为灰色）

如果经过长期记忆的处理，输入则会呈现出如下：

[![pEY51sS.png](https://s21.ax1x.com/2025/03/06/pEY51sS.png)](https://imgse.com/i/pEY51sS)

>   L中一个陈述是否为真，取决于它是否被I映射到M中的一个事实上。
>
>   [Experience-Grounded Semantics: A theory for intelligent systems - Pei Wang]

此机制在本系统中没有体现，我们并不强制要求一个称述必须为真，因为基于经验的系统中，接受的经验并不全是正确的，所以这一点不会在规则中被强制要求。这里只体现了形式语言是如何与模型（语言表达主体）进行对应的。其中认为对模型M（这里是“雪”）的论述，如果事实在经验K中且K存在于系统中，在模型M的事实聚类中性质Z（这里的性质是“白色”）是可触达的，且称述的限定词D（这里是“是”）在事实聚类中会实际存在与一个对模型M的事实称述符号链上。

所以本系统中的形式语言本身就具有经验系统的基本性状——既对错是基于经验的而不是公理性的。

>   Though both are descriptions of an environment (or ”world”), ”model” and ”experience” are different in the following aspects: 
>
>   尽管“模型”和“经验”都是对环境(或“世界”)的描述，但它们在以下方面有所不同: 
>
>   • Amodel is static, whereas experience stretches out over time.  
>
>   • 模型是静态的，而经验则随时间延伸。 
>
>   • A model is a complete description of (the relevant part of) an environment, whereas experience is only a partial description of it. 
>
>   • 模型是对(环境的相关部分)的完整描述，而经验只是对其的部分描述。
>
>    • Amodel must be consistent, whereas judgments in experience may conflict with one another. 
>
>   • 模型必须是一致的，而经验中的判断可能会相互冲突。 
>
>   • Amodel of language L is described in another language Lm, whereas experience can be represented in L itself. 
>
>   • 语言模型L是用另一种语言Lm描述的，而经验可以用L本身来表示。 
>
>   • Theexistence of a model M of L is independent of the existence of a system R using L . Even when both M and R exist, they are not necessarily related to each other in any way. On the contrary, an experience must be the experience of a system. 
>
>   • 模型M的存在独立于使用L的系统R的存在。即使M和R都存在，它们也不一定以任何方式相互关联。相反，经验必须是某个系统的经验
>
>   [Experience-Grounded Semantics: A theory for intelligent systems - Pei Wang]

类似的，本系统中的`记忆`也是随着`训练`或者说`记忆行为`的进行而更迭的，其中满足陈述关系的符号链可能被推翻，也会补充更多的不同模型的性质与经验事实。但好处是，本系统中的记忆原生对多模态数据有所支持，我们可以通过不同模态的符号元素之间的关系来加深系统对于环境的`理解`，如下图：

[![pEYInw4.png](https://s21.ax1x.com/2025/03/06/pEYInw4.png)](https://imgse.com/i/pEYInw4)

（ 注释：这里的图片以及色彩图只是一个示例，我们并没有完全理解和想象如何编制一个感受器能使计算机如人类般拥有眼睛来感受环境，相应的，这个感受器所对应的模态数据我们也没有设计好其形式，故先使用人类眼睛所能接受的图片来直观体现我所想表达的内容）

这也是形式语言的一种体现，我们认为不同形式的符号所构成的形式语言无一例外都是信息的载体，而其本身的区别仅仅只是符号与其聚合形式不同，其传达的信息其实是相同的——如图中的“白”字与白色色块图片，仅仅只是“符号”不同，而传达的信息都是“白”

## 关于推理

>Usually the first three components are referred to as consisting of a logic, while the last two as the implemen tation of the logic in a computer system. 
>
>通常，前三个组件被统称为逻辑，而后两个则被视为逻辑在计算机系统中的实现。 
>
>In such a system, the semantic theory plays two major roles: 
>
>在这样的系统中，语义理论扮演两个主要角色:
>
> • It specifies how the language should be translated into other (natural or artificial) languages in communica tion, so that other (human or computer) systems know how to ”talk” with this system. For this purpose, the semantic theory needs to specify how the meaning of words and sentences of the language is determined by relating them to the outside the language. 
>
>• 它指定了语言应如何在交流中被翻译成其他(自然或人工)语言，以便其他(人或计算机)系统能够 知道如何与该系统“交谈”。为此，语义理论需要指定语言中词汇和句子的意义是如何通过与语言 外部的事物相联系而确定的。 
>
>• It provides justification for the inference rules, that is, to explain why these rules, not others, are proper to be used to carry out inference on the language. For this purpose, the semantic theory needs to specify how the truth value of declarative sentences of the language is determined, so that the rules can be validated as preserving truth in the inference process. 
>
>• 它为推理规则提供正当性，即解释为什么这些规则而不是其他规则适合用于在语言上进行推理。为 此，语义理论需要指定语言中陈述句的真值是如何确定的，以便这些规则可以在推理过程中被验证为保持真值
>
>[Experience-Grounded Semantics: A theory for intelligent systems - Pei Wang]

两个主要角色的第一点上文中有所解释，本部分主要解释第二点与其衍生概念在本系统中的对应概念与实现原理。

系统内部“形式语言”在本系统上唯一的推理规则就是`连接`，本系统的推理仍然不是基于复杂的数学推理进行的，而是模仿LLM的模式，基于统计进行的。但与其不同的是，我们着重考虑了模型论语言学的概念并为其未实现的部分留出了实现空间，这也是真正意义上实现推理的重点。

模型论语言学的三个要素：

1.   模型
2.   真值条件
3.   可能世界

其中模型与真值条件在本系统中的存在在上文中已有论述，本文主要探讨本系统在`可能世界`中的实现想法。

所谓的``被认为在记忆图中是存在的，也是本系统需要着重实现的部分——对模式的捕捉——要实现捕捉经验中存在的潜在模式，并基于这些模式对被推理对象进行分类，且需要能够将被推理对象的信息捕捉使用模式进行递推推理。

其现实世界中存在的例子就是数学学习上的举一反三：通过学习例题——学习例题与其对应的解题过程并推理出模式——这里的模式就是所谓的解题公式。

推测潜在模式的方式，暂且没有固定，就如图数学中根据多个题型的相似点根据代数方法将多个具体情景概念类比到代数环境中，推理出一个共通的模式，也可以使用几何法推理。类似的，推理潜在模式也是一样，可能并不是只存在一种模式可以推测潜在模式，相反的，我认为多种模态一定是存在多种推理模式去推导潜在模式的。

这里提出一种捕捉文字模态中潜在模式的方式——子图法——通过收集经验中的相似子图模式提取潜在模式。推理时将待推理对象按照信息相似度（使用符号链为挂载点在记忆图中执行TopK任务）得到相似的符号链（信息），然后尝试将待推理对象按照相似符号链中提取过的相似子图模式进行排列并分析模式相似度，相似度较高的一对符号链，暂且认为信息相似度较高，故可能后续推理方式——迭代推理图倾向——可能相同，会上调以这个符号链以及其后续子链作为迭代素材的选择权重。

在本项目中，对推理部分的的几个定义：

-   推理规则并不是人为的而是自然形成的
-   推理并不基于符号，而是基于信息进行的
-   推理是一个迭代进行的过程，而不是一步完成的

如上文中子图法进行推理的方式，可以解释推理规则是经验的积累以及潜在子图的积累而自然形成的。同样的，上文中的推理过程也可以论证推理过程本质与符号无关，而是基于信息进行的（之所以我们看不到很多基于图或声音的推理，是因为我们下意识在推理过程中将模态偏向于文字模态进行了转化——因为文字模态信息密度高，也因为长期记忆的大部分信息的载体仍是文字模态）。

至于推理过程，本文认为这与“推理”这个词的含义有关，上文定义中的“推理”的含义是为了达成某个目标，使用现有的知识去尝试实现的过程。而下文中要对本系统实际的推理过程进行叙述以及对上文中“推理”过程的定义进行论证。

>When the system is running, an ”execution cycle”, or ”inference step”, is repeated until the process is interrupted by the user. The cycle consists of the following operation sequence: 
>
>当系统运行时，一个“执行周期”或“推理步骤”会重复进行，直到过程被用户中断。该周期包括以 下操作序列: 
>
>1.To check input buffer. If there are new tasks, put them into the corresponding concepts. 
>
>1.检查输入缓冲区。如果有新任务，将它们放入相应的概念中。 
>
>2.To take out a concept from the concept bag. 
>
>2.从概念包中取出一个概念。 
>
>3.To take out a task from the task bag of the concept. 
>
>3.从概念的任务包中取出一个任务。 
>
>4.To take out a piece of knowledge from the knowledge bag of the concept. 
>
>4.从概念的知识包中取出一条知识。 5. To apply inference rules on the task and knowledge. Which rule is applicable is determined by the combi nation of the task and the knowledge. 
>
>5.对任务和知识应用推理规则。适用哪条规则由任务和知识的组合决定。 
>
>6.To adjust the priority and durability values of the given task, knowledge, and concept, according to the quality of the results. Then the task, knowledge, and concept are returned to the corresponding bags. 
>
>6.根据结果的质量，调整给定任务、知识和概念的优先级和耐用性值。然后将任务、知识和概念返回到相应的包中。
>
>7.Toputtheresults generated in this step into the input buffer as new tasks. If a result happen to be a best-so-far answer of a question asked by the user, it is reported to the user. 
>
>7.将此步骤生成的结果放入输入缓冲区作为新任务。如果某个结果恰好是用户提出问题的迄今为止的最佳答案，则将其报告给用户。
>
>[ Computation and Intelligence in Problem Solving - Pei Wang]

本系统中的推理过程与此类似，也是一个循环进行的推理周期。

[![pEYHBVS.png](https://s21.ax1x.com/2025/03/06/pEYHBVS.png)](https://imgse.com/i/pEYHBVS)

不同的是，其推理过程的终止只与回忆阈值相关

>另外，回忆系统是具有阈值的系统，回忆是一个类似`Top K`的任务，其区分度就是回忆系统的阈值，阈值就是系统对结果的最低采用度，这个阈值决定了“认知固化”的发生可能，在基于当前回忆挂载点形成的符号链进行的回忆结果全部都低于阈值时，将没有内容会输出。
>
>[突发奇想的新架构 - Elimir]

当前认为当没有回忆时没有内容输出发生时，当前结果就是基于当前系统内全部相关经验对推理任务进行推理所能够产生的最好结果。需要注意的是系统本身对于推理结果是否正确以及是否完整是不存在辨别能力的（如果不将判断本推理过程是否完整或正确也作为推理任务），只能基于当前上下文进行输出推理。

## 展望以及存疑

### 展望

本研究认为以图为基底数据结构进行设计的原生LLM模型才是实现具有原生多模态能力的LLM模型的最好途径，同时也是实现具有类人的学习能力以及推理能力的LLM模型的最好途径。

现在的LLM的CoT推理模式仍然是基于对Prompt工程，尝试对中间推理过程补全后对于论域进行更深层次的划定，从而减少幻觉和增加推理能力，但本质还是基于历史数据集，虽然太阳底下无新事，但本文认为当前互联网上的所有数据的总和仍不能做到穷举所有现实问题的细节情况以及其解决方案，故此种提升方案对于历史重复性高，重演可能性高的任务改善可能较大，但对于解决实际生活中的复杂情景问题的提升还是非常有限。

所以，本研究认为基于图研究如何实现原生的基于经验的推理模式，才是实现agi类人推理能力与学习能力的破局点。

### 存疑

暂不明确当前提出的系统中的记忆机制的实际在大量生活数据构建的记忆图是否能够正确达成一部分推理能力，对于记忆图的存在形式以及符号链的记忆保存模式还是存疑。可能符号链并不单纯按照时间和关系进行储存，还需要根据当前经验划分出子链，将子链进行存储。

[![pEYbUJJ.png](https://s21.ax1x.com/2025/03/06/pEYbUJJ.png)](https://imgse.com/i/pEYbUJJ)

如图，曾经本研究认为子链能够构成的强链接子链（强聚合子链）应该从图中提取并上升一个层次，将强聚合子链作为节点，连接则是强聚合子链之间的连接。在回忆时自上向下进行回忆操作，可以在符号层面而不是模式层面进行信息聚合。

本研究还认为可以潜在模式也可以作为一个层面提取并作为回忆或推理的信息来源，但是否具有工程有效性和结果有效性尚不明晰，需要进一步进行工程实验，故存疑。
